{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Chart Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "import pandas\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image( infilename ) :\n",
    "    img = Image.open( infilename )\n",
    "    img.load()\n",
    "    data = np.asarray( img, dtype=\"float32\" )\n",
    "    return data\n",
    "\n",
    "data_dir = 'charts_data'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144 images belonging to 6 classes.\n",
      "Found 43 images belonging to 6 classes.\n",
      "Found 64 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height = 224, 224\n",
    "batch_size = 5\n",
    "epochs = 10\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./224)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1./224)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size, \n",
    "    class_mode = \"categorical\")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    valid_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    class_mode = \"categorical\")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_model = applications.VGG19(weights = \"imagenet\", \n",
    "                           include_top=False, \n",
    "                           input_shape = (img_width, img_height, 3))\n",
    "for layer in vgg_model.layers[:5]:\n",
    "    layer.trainable = False\n",
    "x = vgg_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "predictions = Dense(6, activation='softmax')(x)\n",
    "model_final = Model(inputs=vgg_model.input, outputs=predictions)\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False\n",
    "model_final.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "28/28 [==============================] - 94s - loss: 1.2474 - val_loss: 0.6858\n",
      "Epoch 2/8\n",
      "28/28 [==============================] - 78s - loss: 0.4997 - val_loss: 0.6079\n",
      "Epoch 3/8\n",
      "28/28 [==============================] - 90s - loss: 0.3232 - val_loss: 0.3809\n",
      "Epoch 4/8\n",
      "28/28 [==============================] - 78s - loss: 0.2125 - val_loss: 0.1073\n",
      "Epoch 5/8\n",
      "28/28 [==============================] - 93s - loss: 0.1222 - val_loss: 0.1346\n",
      "Epoch 6/8\n",
      "28/28 [==============================] - 84s - loss: 0.0876 - val_loss: 0.1606\n",
      "Epoch 7/8\n",
      "28/28 [==============================] - 92s - loss: 0.0720 - val_loss: 0.0568\n",
      "Epoch 8/8\n",
      "28/28 [==============================] - 78s - loss: 0.0810 - val_loss: 0.0451\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb25f13a10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs = 8,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = validation_generator.samples/validation_generator.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "27/28 [===========================>..] - ETA: 2s - loss: 0.0367 - acc: 1.0000Epoch 00000: val_acc improved from -inf to 1.00000, saving model to chart_vgg19_wt.h5\n",
      "28/28 [==============================] - 91s - loss: 0.0395 - acc: 1.0000 - val_loss: 0.0512 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      "27/28 [===========================>..] - ETA: 2s - loss: 0.0273 - acc: 1.0000Epoch 00001: val_acc did not improve\n",
      "28/28 [==============================] - 78s - loss: 0.0275 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      "27/28 [===========================>..] - ETA: 2s - loss: 0.0302 - acc: 1.0000Epoch 00002: val_acc did not improve\n",
      "28/28 [==============================] - 92s - loss: 0.0296 - acc: 1.0000 - val_loss: 0.0404 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      "27/28 [===========================>..] - ETA: 2s - loss: 0.0275 - acc: 1.0000Epoch 00003: val_acc did not improve\n",
      "28/28 [==============================] - 79s - loss: 0.0277 - acc: 1.0000 - val_loss: 0.0695 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "27/28 [===========================>..] - ETA: 2s - loss: 0.0155 - acc: 1.0000Epoch 00004: val_acc did not improve\n",
      "28/28 [==============================] - 91s - loss: 0.0154 - acc: 1.0000 - val_loss: 0.0483 - val_acc: 1.0000\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb2155bad0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"chart_vgg19_wt.h5\", \n",
    "                             monitor='val_acc', verbose=2, \n",
    "                             save_best_only=True, save_weights_only=False, \n",
    "                             mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', \n",
    "                      min_delta=0, patience=3, \n",
    "                      verbose=2, mode='auto')\n",
    "layer_num = len(model_final.layers)\n",
    "for layer in model_final.layers[:21]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in model_final.layers[21:]:\n",
    "    layer.trainable = True\n",
    "model_final.compile(optimizer=optimizers.Adam(lr=0.0001), \n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_final.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples/train_generator.batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = validation_generator.samples/validation_generator.batch_size,\n",
    "    callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_final.save('chart_vgg19_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (p2)",
   "language": "python",
   "name": "p2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
