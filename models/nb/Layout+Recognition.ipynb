{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Layout Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "EndFontMetrics quoteleft 15 150575000 407 700 ;754 ;;;on. All rights reserved. GE Inspira is a trademark of the General Electric Company.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "import pandas\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image( infilename ) :\n",
    "    img = Image.open( infilename )\n",
    "    img.load()\n",
    "    data = np.asarray( img, dtype=\"float32\" )\n",
    "    return data\n",
    "\n",
    "data_dir = 'layout_data'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23 images belonging to 2 classes.\n",
      "Found 9 images belonging to 2 classes.\n",
      "Found 8 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height = 224, 224\n",
    "batch_size = 3\n",
    "epochs = 10\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./224\n",
    "    )\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1./224\n",
    "    )\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size, \n",
    "    class_mode = \"categorical\")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    valid_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    class_mode = \"categorical\")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_model = applications.VGG19(weights = \"imagenet\", \n",
    "                           include_top=False, \n",
    "                           input_shape = (img_width, img_height, 3))\n",
    "for layer in vgg_model.layers[:5]:\n",
    "    layer.trainable = False\n",
    "x = vgg_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model_final = Model(inputs=vgg_model.input, outputs=predictions)\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False\n",
    "model_final.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 30s - loss: 1.0967 - val_loss: 0.9325\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 27s - loss: 0.5691 - val_loss: 0.5195\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 27s - loss: 0.5281 - val_loss: 0.3604\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 27s - loss: 0.3833 - val_loss: 0.3382\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 27s - loss: 0.2794 - val_loss: 0.2291\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 28s - loss: 0.2094 - val_loss: 0.1488\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 28s - loss: 0.1415 - val_loss: 0.1869\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 27s - loss: 0.1740 - val_loss: 0.0881\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 28s - loss: 0.0628 - val_loss: 0.0636\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 28s - loss: 0.0914 - val_loss: 0.0643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb22f49cd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = validation_generator.samples/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0574 - acc: 1.0000Epoch 00000: val_acc improved from -inf to 1.00000, saving model to layout_vgg19_wt.h5\n",
      "7/7 [==============================] - 30s - loss: 0.0560 - acc: 1.0000 - val_loss: 0.0444 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0393 - acc: 1.0000Epoch 00001: val_acc did not improve\n",
      "7/7 [==============================] - 28s - loss: 0.0391 - acc: 1.0000 - val_loss: 0.0412 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0561 - acc: 1.0000Epoch 00002: val_acc did not improve\n",
      "7/7 [==============================] - 27s - loss: 0.0517 - acc: 1.0000 - val_loss: 0.0389 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0385 - acc: 1.0000Epoch 00003: val_acc did not improve\n",
      "7/7 [==============================] - 28s - loss: 0.0352 - acc: 1.0000 - val_loss: 0.0363 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.0415 - acc: 1.0000Epoch 00004: val_acc did not improve\n",
      "7/7 [==============================] - 27s - loss: 0.0390 - acc: 1.0000 - val_loss: 0.0344 - val_acc: 1.0000\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb1dd3cb50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"layout_vgg19_wt.h5\", \n",
    "                             monitor='val_acc', verbose=2, \n",
    "                             save_best_only=True, save_weights_only=False, \n",
    "                             mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', \n",
    "                      min_delta=0, patience=3, \n",
    "                      verbose=2, mode='auto')\n",
    "layer_num = len(model_final.layers)\n",
    "for layer in model_final.layers[:21]:\n",
    "    layer.trainable = False\n",
    "for layer in model_final.layers[21:]:\n",
    "    layer.trainable = True\n",
    "model_final.compile(optimizer=optimizers.Adam(lr=0.0001), \n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_final.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples/train_generator.batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = validation_generator.samples/batch_size,\n",
    "    callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_final.save('layout_vgg19_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:p2]",
   "language": "python",
   "name": "conda-env-p2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
